nohup: ignoring input
[2024-05-11 01:43:24,574] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/root/anaconda3/envs/deepseek/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m NVIDIA Inference is only supported on Ampere and newer architectures
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|â–ˆâ–        | 1/7 [00:11<01:06, 11.16s/it]Loading checkpoint shards:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:23<00:59, 11.83s/it]Loading checkpoint shards:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3/7 [00:35<00:48, 12.06s/it]Loading checkpoint shards:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:48<00:36, 12.20s/it]Loading checkpoint shards:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [01:00<00:24, 12.29s/it]Loading checkpoint shards:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [01:13<00:12, 12.40s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:19<00:00, 10.34s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:19<00:00, 11.34s/it]
Memory occupied by parameters: 31234.22265625 MB
[2, 5, 2, 0, 4, 0, 7, 1, 4, 1, 3, 5, 5, 7, 0, 4, 7, 5, 1, 3, 0, 7, 0, 5, 5, 0, 2]
0
self.max_expert 2
previous tensor([[ 2, 14, 34, 42, 47,  1],
        [14, 34, 37, 40, 42, 24]], device='cuda:0')
after tensor([[64, 14, 34, 42, 47,  1],
        [14, 34, 37, 40, 42, 24]], device='cuda:0')
self.max_expert 5
previous tensor([[14, 31, 42, 46, 63, 61],
        [11, 17, 41, 55, 61, 48]], device='cuda:0')
after tensor([[14, 31, 42, 46, 63, 61],
        [11, 17, 41, 55, 61, 48]], device='cuda:0')
self.max_expert 2
previous tensor([[20, 22, 41, 46, 62, 31],
        [13, 19, 25, 31, 56, 26]], device='cuda:0')
after tensor([[20, 22, 41, 46, 62, 31],
        [13, 19, 25, 31, 56, 26]], device='cuda:0')
self.max_expert 0
previous tensor([[ 0, 18, 43, 62,  1, 17],
        [12, 15, 19, 26, 38, 43]], device='cuda:0')
after tensor([[64, 18, 43, 62,  1, 17],
        [12, 15, 19, 26, 38, 43]], device='cuda:0')
self.max_expert 4
previous tensor([[ 7, 12, 13, 24, 36, 16],
        [26, 33, 42, 49, 53, 16]], device='cuda:0')
after tensor([[ 7, 12, 13, 24, 36, 16],
        [26, 33, 42, 49, 53, 16]], device='cuda:0')
self.max_expert 0
previous tensor([[19, 29, 45, 48, 63, 27],
        [19, 32, 39, 46, 60, 22]], device='cuda:0')
after tensor([[19, 29, 45, 48, 63, 27],
        [19, 32, 39, 46, 60, 22]], device='cuda:0')
self.max_expert 7
previous tensor([[17, 21, 45, 53, 55, 12],
        [23, 35, 38, 47, 55, 33]], device='cuda:0')
after tensor([[17, 21, 45, 53, 55, 12],
        [23, 35, 38, 47, 55, 33]], device='cuda:0')
self.max_expert 1
previous tensor([[18, 43, 44, 49, 62, 35],
        [ 5, 11, 40, 58, 63,  3]], device='cuda:0')
after tensor([[18, 43, 44, 49, 62, 35],
        [ 5, 11, 40, 58, 63,  3]], device='cuda:0')
self.max_expert 4
previous tensor([[10, 36, 43, 49, 61, 33],
        [ 0, 11, 30, 46, 51, 21]], device='cuda:0')
after tensor([[10, 36, 43, 49, 61, 33],
        [ 0, 11, 30, 46, 51, 21]], device='cuda:0')
self.max_expert 1
previous tensor([[ 0, 24, 33, 42, 45, 63],
        [ 0,  8, 40, 41, 56, 25]], device='cuda:0')
after tensor([[ 0, 24, 33, 42, 45, 63],
        [ 0,  8, 40, 41, 56, 25]], device='cuda:0')
self.max_expert 3
previous tensor([[ 2, 24, 37, 42, 53, 58],
        [14, 37, 38, 56, 58, 44]], device='cuda:0')
after tensor([[ 2, 24, 37, 42, 53, 58],
        [14, 37, 38, 56, 58, 44]], device='cuda:0')
self.max_expert 5
previous tensor([[ 1, 33, 36, 48, 50, 17],
        [21, 33, 46, 50, 54, 25]], device='cuda:0')
after tensor([[ 1, 33, 36, 48, 50, 17],
        [21, 33, 46, 50, 54, 25]], device='cuda:0')
self.max_expert 5
previous tensor([[ 7, 17, 39, 47, 51, 22],
        [13, 24, 29, 51, 58,  9]], device='cuda:0')
after tensor([[ 7, 17, 39, 47, 51, 22],
        [13, 24, 29, 51, 58,  9]], device='cuda:0')
self.max_expert 7
previous tensor([[ 3,  4,  5, 35, 37, 10],
        [ 0, 14, 47, 58, 60, 44]], device='cuda:0')
after tensor([[ 3,  4,  5, 35, 37, 10],
        [ 0, 14, 47, 58, 60, 44]], device='cuda:0')
self.max_expert 0
previous tensor([[ 3, 16, 24, 27, 35, 19],
        [ 8, 11, 12, 17, 50, 49]], device='cuda:0')
after tensor([[ 3, 16, 24, 27, 35, 19],
        [ 8, 11, 12, 17, 50, 49]], device='cuda:0')
self.max_expert 4
previous tensor([[ 1,  3,  8, 10, 23, 37],
        [29, 36, 48, 50, 51, 23]], device='cuda:0')
after tensor([[ 1,  3,  8, 10, 23, 37],
        [29, 36, 48, 50, 51, 23]], device='cuda:0')
self.max_expert 7
previous tensor([[22, 24, 37, 44, 61, 11],
        [34, 38, 41, 54, 61, 26]], device='cuda:0')
after tensor([[22, 24, 37, 44, 61, 11],
        [34, 38, 41, 54, 61, 26]], device='cuda:0')
self.max_expert 5
previous tensor([[ 2, 44, 47, 50, 61, 15],
        [ 4,  7, 15, 18, 59, 47]], device='cuda:0')
after tensor([[ 2, 44, 47, 50, 61, 15],
        [ 4,  7, 15, 18, 59, 47]], device='cuda:0')
self.max_expert 1
previous tensor([[ 9, 10, 17, 45, 51, 25],
        [15, 26, 39, 45, 51, 20]], device='cuda:0')
after tensor([[ 9, 10, 17, 45, 51, 25],
        [15, 26, 39, 45, 51, 20]], device='cuda:0')
self.max_expert 3
previous tensor([[15, 30, 49, 53, 59, 40],
        [16, 27, 32, 34, 41, 49]], device='cuda:0')
after tensor([[15, 30, 49, 53, 59, 40],
        [16, 27, 32, 34, 41, 49]], device='cuda:0')
self.max_expert 0
previous tensor([[16, 29, 31, 48, 59, 43],
        [ 7, 16, 34, 60, 61,  4]], device='cuda:0')
after tensor([[16, 29, 31, 48, 59, 43],
        [ 7, 16, 34, 60, 61,  4]], device='cuda:0')
self.max_expert 7
previous tensor([[18, 23, 53, 56, 59,  4],
        [ 1, 16, 23, 30, 57, 27]], device='cuda:0')
after tensor([[18, 23, 53, 56, 59,  4],
        [ 1, 16, 23, 30, 57, 27]], device='cuda:0')
self.max_expert 0
previous tensor([[10, 21, 32, 50, 59, 18],
        [ 4, 23, 33, 34, 46, 60]], device='cuda:0')
after tensor([[10, 21, 32, 50, 59, 18],
        [ 4, 23, 33, 34, 46, 60]], device='cuda:0')
self.max_expert 5
previous tensor([[11, 18, 37, 49, 59, 23],
        [ 3, 13, 29, 39, 45, 51]], device='cuda:0')
after tensor([[11, 18, 37, 49, 59, 23],
        [ 3, 13, 29, 39, 45, 51]], device='cuda:0')
self.max_expert 5
previous tensor([[ 2, 41, 49, 60, 63, 30],
        [ 2, 30, 52, 57, 63, 24]], device='cuda:0')
after tensor([[ 2, 41, 49, 60, 63, 30],
        [ 2, 30, 52, 57, 63, 24]], device='cuda:0')
self.max_expert 0
previous tensor([[31, 33, 40, 45, 57, 39],
        [10, 12, 23, 46, 50, 16]], device='cuda:0')
after tensor([[31, 33, 40, 45, 57, 39],
        [10, 12, 23, 46, 50, 16]], device='cuda:0')
self.max_expert 2
previous tensor([[14, 30, 54, 56, 62,  2],
        [19, 27, 38, 53, 55,  1]], device='cuda:0')
after tensor([[14, 30, 54, 56, 62,  2],
        [19, 27, 38, 53, 55,  1]], device='cuda:0')
